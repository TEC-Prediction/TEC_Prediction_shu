[global]
seed = 13
predict_range = global
; global or globalSH or single point (Longitude, latitude)
device = cuda
; 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

[train]
epoch = 100
batch_size = 64
lr = 1e-5
shuffle = True
num_worker = 0
criterion = RMSELoss
optimizer = SGD
lr_scheduler = ReduceLROnPlateau
; CosineAnnealingLR
; ReduceLROnPlateau
; OneCycleLR
[eval]
batch_size = 4
shuffle = False
num_worker = 0

[preprocess]
normalization_type = min_max
; min_max
; z_score
; None
predict_norm = False
; False if normalization_type = None

[data]

train_year = 2018, 2019
test_year = 2020, 2021
valid_ratio = 0.8

dataset_type = SWGIMDataset

max_seq_length = 512
reduce = False
reduce_ratio = 0.2
reserved = 0
; ISSUE: reserved truth detach error
[model]
model_name = Transformer_encoder_GTEC
; LSTM_TEC
; LSTM_TEC_2SW
; LSTM_Seq2Seq_TEC
; LSTM_Seq2Seq_TEC_2SW
; Transformer_encoder_GTEC
; Transformer_GTEC
input_time_step = 24
; model input x hours TEC
output_time_step = 4
; model output x-hour-later TEC
embedding_size = 512
; ignore in Transformer (equal to hidden_size)
; for seq2seq model
hidden_size = 384
num_layer = 1
dropout = 0.1

[output]
output_func = SWGIM
rounding_digit = 5